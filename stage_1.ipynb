{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36fb009",
   "metadata": {},
   "source": [
    "# Stage 1 - Data Preparation and Research Question Defining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1f09b",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2695e",
   "metadata": {},
   "source": [
    "### Data Acquisition and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a2797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(\"all_stocks.csv\")\n",
    "# Create combined dataframe and write to CSV if not found\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame()\n",
    "    data_path = Path(\"./sp500/\")\n",
    "    stock_files = sorted(data_path.glob(\"*.csv\"))\n",
    "    \n",
    "    \n",
    "    for file in stock_files:\n",
    "        df_stock = pd.read_csv(file).assign(stock=file.stem)\n",
    "        df = pd.concat([df, df_stock], ignore_index=True)\n",
    "\n",
    "    # We choose records from 2018-2022\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst = True, format=\"%d-%m-%Y\")\n",
    "    df = df[(df[\"Date\"] >= \"2018-01-01\") & (df[\"Date\"] <= \"2022-12-31\")]\n",
    "    df.to_csv(\"all_stocks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547500d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee80d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stock column as categorical data\n",
    "df[\"stock\"] = df[\"stock\"].astype(\"category\")\n",
    "\n",
    "# Check for missing values by stock\n",
    "def summary_na(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    summary = (\n",
    "        df.assign(any_na=df.isna().any(axis=1))\n",
    "        .groupby(\"stock\", observed=True)\n",
    "        .agg(rows=(\"any_na\", \"size\"),\n",
    "            rows_any_na=(\"any_na\", \"sum\"))\n",
    "        .assign(rate_any_na=lambda d: d[\"rows_any_na\"] / d[\"rows\"])\n",
    "        .sort_values(\"rate_any_na\", ascending=False)\n",
    "    )\n",
    "    return summary\n",
    "\n",
    "summary = summary_na(df)\n",
    "print(summary[summary[\"rate_any_na\"] != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791ed5f",
   "metadata": {},
   "source": [
    "The rate of missing value in `CTQ`, `BHI`, `SONC`, `CPICQ` is too high, we decide to drop these stocks, for the rest of stocks, we might apply interpolate in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0137db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"stock\"].isin([\"CTQ\", \"BHI\", \"SONC\", \"CPICQ\"])].copy()\n",
    "\n",
    "summary_na_dropped = summary_na(df)\n",
    "print(summary_na_dropped[summary_na_dropped[\"rate_any_na\"] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rest Missing Values in rows\n",
    "na_rows = df[df.isna().any(axis=1)].copy()\n",
    "na_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c424b",
   "metadata": {},
   "source": [
    "The missing values are located in the last few months of stock data. We simply drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06172a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Volume'] = df['Volume'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f64777",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    df[col] = df[col].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d7ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"all_stocks_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d8b486",
   "metadata": {},
   "source": [
    "### Compute features for trading strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"MA_5\",\"MA_10\",\"MA_20\",\"MA_60\",\"MA_120\",\"MA_180\", \"MA_signal\", \"MA_Weight\", \"MA_Position\", \"Upper_Band_20\", \"Lower_Band_20\", \"Upper_Band_60\", \"Lower_Band_60\", \"BB_signal\", \"BB_Position\", \"BB_Weight\"]\n",
    "df_samples = pd.DataFrame(columns=df.columns.tolist() + cols)\n",
    "sid = 0\n",
    "\n",
    "df_grouped = df.groupby('stock')\n",
    "for name, group in df_grouped:\n",
    "    # Calculate moving averages for 5, 10, 20, 60, 120, 180\n",
    "    group[\"MA_5\"] = group[\"Close\"].rolling(window=5).mean()\n",
    "    group[\"MA_10\"] = group[\"Close\"].rolling(window=10).mean()\n",
    "    group[\"MA_20\"] = group[\"Close\"].rolling(window=20).mean()\n",
    "    group[\"MA_60\"] = group[\"Close\"].rolling(window=60).mean()\n",
    "    group[\"MA_120\"] = group[\"Close\"].rolling(window=120).mean()\n",
    "    group[\"MA_180\"] = group[\"Close\"].rolling(window=180).mean()\n",
    "    group[\"MA_signal\"] = 0\n",
    "    group[\"MA_Weight\"] = 0\n",
    "    group[\"MA_Position\"] = 0\n",
    "\n",
    "    # Bollinger (window=20, k=2, ddof=0) (window=60, k=2.5, ddof=0)\n",
    "    sd20 = group[\"Close\"].rolling(20, min_periods=20).std(ddof=0)\n",
    "    sd60 = group[\"Close\"].rolling(60, min_periods=60).std(ddof=0)\n",
    "    group[\"Upper_Band_20\"] = group[\"MA_20\"] + 2.0 * sd20\n",
    "    group[\"Lower_Band_20\"] = group[\"MA_20\"] - 2.0 * sd20\n",
    "    group[\"Upper_Band_60\"] = group[\"MA_60\"] + 2.5 * sd60\n",
    "    group[\"Lower_Band_60\"] = group[\"MA_60\"] - 2.5 * sd60\n",
    "    group[\"BB_signal\"] = 0\n",
    "    group[\"BB_Position\"] = 0\n",
    "    group[\"BB_Weight\"] = 0\n",
    "\n",
    "    df.loc[group.index, cols] = group[cols]\n",
    "\n",
    "    Window_size = 180\n",
    "    Pace = 90\n",
    "    Padding = 180\n",
    "    \n",
    "    n = len(group)\n",
    "    for i in range(Padding, n - Window_size + 1, Pace):\n",
    "        sub = group.iloc[i:i+Window_size][df.columns.tolist()].copy()\n",
    "        sub[\"sample_id\"] = sid\n",
    "        sid += 1\n",
    "        df_samples = pd.concat([df_samples, sub], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples = df_samples[[\"sample_id\"] + [c for c in df_samples.columns if c != \"sample_id\"]]\n",
    "df_samples[\"sample_id\"] = df_samples[\"sample_id\"].astype(int)\n",
    "df_samples.to_csv(\"time_period_samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading Strategy Backtesting\n",
    "from TradingStrategies import ma_strategy, backtest_ma_strategy, bb_strategy, backtest_bb_strategy\n",
    "# MA Crossover Strategy\n",
    "results = pd.DataFrame(columns=['sample_id', 'MA_sharpe', 'MA_cagr', 'MA_mdd', 'BB_sharpe', 'BB_cagr', 'BB_mdd'])\n",
    "ma_pairs = [(5, 20), (10, 60), (20, 120), (60, 180)]\n",
    "\n",
    "for name, group in df_samples.groupby('sample_id'):\n",
    "    group = ma_strategy(group, ma_signals=ma_pairs)\n",
    "    MA_sharpe, MA_cagr, MA_mdd = backtest_ma_strategy(group)\n",
    "\n",
    "    group = bb_strategy(group)\n",
    "    BB_sharpe, BB_cagr, BB_mdd = backtest_bb_strategy(group)\n",
    "    results = pd.concat([results, pd.DataFrame({'sample_id': [name], 'MA_sharpe': [MA_sharpe], 'MA_cagr': [MA_cagr], 'MA_mdd': [MA_mdd], 'BB_sharpe': [BB_sharpe], 'BB_cagr': [BB_cagr], 'BB_mdd': [BB_mdd]})], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d785ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = (results['MA_sharpe'] > 1).mean()\n",
    "prop2 = (results['MA_cagr'] > 0.05).mean()\n",
    "print(prop)\n",
    "print(prop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26757eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = (results['BB_sharpe'] > 1).mean()\n",
    "prop2 = (results['BB_cagr'] > 0.05).mean()\n",
    "print(prop)\n",
    "print(prop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop = ((results['BB_sharpe'] > 1) & (results['MA_sharpe'] < 1)).mean() / (results['BB_sharpe'] > 1).mean()\n",
    "\n",
    "print(prop)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
